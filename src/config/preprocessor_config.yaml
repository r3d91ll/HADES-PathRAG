# Centralized pre-processor configuration for HADES-PathRAG
# Edit this YAML file to change pre-processor behavior.

version: 1
exclude_patterns:
  - __pycache__
  - .git
recursive: true
max_workers: 12
# File type mapping and categorization
# Each file type is mapped to its extensions and categorized as either 'code' or 'text'
file_type_map:
  # Code formats (processed with AST/symbol table methods)
  python: ['.py']
  # javascript: ['.js', '.jsx', '.ts', '.tsx']
  # java: ['.java']
  # cpp: ['.cpp', '.hpp', '.cc', '.h']
  json: ['.json']
  yaml: ['.yaml', '.yml']
  xml: ['.xml']
  toml: ['.toml']
  
  # Text formats (processed with docling/chonky methods)
  markdown: ['.md', '.markdown']
  pdf: ['.pdf']
  csv: ['.csv']
  text: ['.txt']
  # html: ['.html', '.htm']
  docx: ['.docx']
  xlsx: ['.xlsx']
  pptx: ['.pptx']

# Content category mapping
content_categories:
  code: ['python', 'json', 'yaml', 'xml', 'toml']
  text: ['markdown', 'pdf', 'csv', 'text', 'docx', 'xlsx', 'pptx']

# Format-specific processing options
preprocessor_config:
  # Python code processing options
  python:
    create_symbol_table: true
    extract_docstrings: true
    analyze_imports: true
    # Add call graph analysis
    analyze_calls: true
    # Extract type hints from annotations
    extract_type_hints: true
    # Extract complexity metrics
    compute_complexity: false
  
  # Markdown processing options
  markdown:
    extract_mermaid: true
    extract_code_blocks: true
    extract_links: true
    # Extract headings to create document structure
    extract_headings: true
    # Extract tables into structured data
    extract_tables: true
    # Identify and tag code snippets by language
    identify_code_languages: true
  
  # PDF processing options
  pdf:
    # Use OCR for scanned documents
    use_ocr: true
    # OCR language (default is English, can be 'eng+fra' for multiple)
    ocr_languages: 'eng'
    # Extract figures and captions
    extract_figures: true
    # Extract tables
    extract_tables: true
    # Parse document structure (headings, sections)
    parse_structure: true
  
  # JSON processing options
  json:
    # Validate against schemas
    validate_schemas: false
    # Schema directory for validation
    schema_directory: ''
    # Extract nested structures
    extract_nested: true
  
  # Text processing options
  text:
    # Detect and normalize line endings
    normalize_line_endings: true
    # Detect language
    detect_language: true
    # Remove duplicate whitespace
    clean_whitespace: true

# Global metadata extraction options
metadata_extraction:
  # Extract title from content if not in metadata
  extract_title: true
  # Extract author information if available
  extract_authors: true
  # Extract publication date if available
  extract_date: true
  # Use filename as fallback title
  use_filename_as_title: true
  # Extract language information
  detect_language: true

# Global entity extraction options
entity_extraction:
  # Extract named entities (people, organizations, etc)
  extract_named_entities: true
  # Extract technical terms
  extract_technical_terms: true
  # Minimum confidence for entity extraction
  min_confidence: 0.7

# Integration with chunking pipeline
chunking_preparation:
  # Add section markers for better chunking
  add_section_markers: true
  # Preserve metadata in chunks
  preserve_metadata: true
  # Mark potential chunk boundaries
  mark_chunk_boundaries: true

options: {}
