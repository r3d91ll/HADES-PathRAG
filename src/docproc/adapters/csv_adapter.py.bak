"""
CSV adapter for document processing.

This module provides functionality to process CSV documents.
"""

import csv
import hashlib
import re
from pathlib import Path
from typing import Dict, Any, Optional, List, Union, Iterator

from .base import BaseAdapter
from .registry import register_adapter


class CSVAdapter(BaseAdapter):
    """Adapter for processing CSV documents."""
    
    def __init__(self, options: Optional[Dict[str, Any]] = None):
        """
        Initialize the CSV adapter.
        
        Args:
            options: Optional configuration options
        """
        self.options = options or {}
    
    def process(self, file_path: Path, options: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Process a CSV file.
        
        Args:
            file_path: Path to the CSV file
            options: Optional processing options
            
        Returns:
            Dictionary with processed content and metadata
        """
        process_options = {**self.options, **(options or {})}
        
        # Verify the file exists
        if not file_path.exists():
            raise FileNotFoundError(f"CSV file not found: {file_path}")
        
        # Generate a stable document ID
        file_path_str = str(file_path)
        file_name = file_path.name
        file_name_sanitized = re.sub(r"[^A-Za-z0-9_:\-@\.\(\)\+\,=;\$!\*'%]+", "_", file_name)
        doc_id = f"csv_{hashlib.md5(file_path_str.encode()).hexdigest()[:8]}_{file_name_sanitized}"
        
        try:
            # Read the CSV file
            with open(file_path, 'r', encoding='utf-8', newline='') as f:
                # Try to detect the delimiter
                try:
                    delimiter = self._detect_delimiter(f)
                    f.seek(0)  # Reset file pointer to beginning
                except Exception:
                    delimiter = ','
                    f.seek(0)  # Reset file pointer to beginning
                
                # Parse the CSV with the detected delimiter
                try:
                    reader = csv.reader(f, delimiter=delimiter)
                    data = list(reader)
                except Exception:
                    # Fallback to a simple line-by-line reading
                    f.seek(0)
                    data = [line.strip().split(delimiter) for line in f if line.strip()]
            
            # Ensure we have at least some data
            if not data:
                data = [[]]  # Empty header to avoid index errors
                
            # Get header row
            header = data[0] if data else []
            
            # Convert rows to dictionaries if we have headers
            records = []
            if header and len(data) > 1:
                for row in data[1:]:
                    # Ensure row has same length as header by padding or truncating
                    padded_row = row + [''] * (len(header) - len(row)) if len(row) < len(header) else row[:len(header)]
                    records.append(dict(zip(header, padded_row)))
            
            # Create structured representation
            structured_data = {
                "header": header,
                "rows": data[1:] if len(data) > 1 else [],
                "records": records
            }
            
            # Convert to markdown for readability
            markdown_content = self.to_markdown(structured_data)
            
            # Extract metadata
            metadata = self.extract_metadata(structured_data)
            
            # Extract entities
            entities = self.extract_entities(structured_data)
            
            return {
                "id": doc_id,
                "source": str(file_path),
                "content": markdown_content,
                "content_type": "markdown",
                "format": "csv",
                "metadata": metadata,
                "entities": entities,
                "structured_data": structured_data  # Store the parsed data
            }
            
        except Exception as e:
            raise ValueError(f"Error processing CSV file {file_path}: {e}")
    
    def process_text(self, text: str, options: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Process CSV text content.
        
        Args:
            text: CSV text content to process
            options: Optional processing options
            
        Returns:
            Dictionary with processed content and metadata
        """
        process_options = {**self.options, **(options or {})}
        
        # Generate a stable document ID
        doc_id = f"csv_text_{hashlib.md5(text[:100].encode()).hexdigest()[:8]}"
        
        try:
            # Detect delimiter
            delimiter = process_options.get('delimiter', self._detect_delimiter_from_text(text))
            
            # Parse the CSV
            lines = text.splitlines()
            reader = csv.reader(lines, delimiter=delimiter)
            data = list(reader)
            
            # Get header row
            header = data[0] if len(data) > 0 else []
            
            # Convert rows to dictionaries if we have headers
            records = []
            if header and len(data) > 1:
                for row in data[1:]:
                    # Ensure row has same length as header by padding or truncating
                    padded_row = row + [''] * (len(header) - len(row)) if len(row) < len(header) else row[:len(header)]
                    records.append(dict(zip(header, padded_row)))
            
            # Create structured representation
            structured_data = {
                "header": header,
                "rows": data[1:] if len(data) > 1 else [],
                "records": records
            }
            
            # Convert to markdown for readability
            markdown_content = self.to_markdown(structured_data)
            
            # Extract metadata
            metadata = self.extract_metadata(structured_data)
            
            # Extract entities
            entities = self.extract_entities(structured_data)
            
            return {
                "id": doc_id,
                "source": "text",
                "content": markdown_content,
                "content_type": "markdown",
                "format": "csv",
                "metadata": metadata,
                "entities": entities,
                "structured_data": structured_data  # Store the parsed data
            }
            
        except Exception as e:
            raise ValueError(f"Error processing CSV text: {e}")
    
    def extract_entities(self, content: Union[str, Dict[str, Any], Any]) -> List[Dict[str, Any]]:
        """
        Extract entities from CSV content.
        
        Args:
            content: CSV content as string, dict, or parsed CSV
            
        Returns:
            List of extracted entities with metadata
        """
        entities: List[Dict[str, Any]] = []
        
        # Handle different content types
        structured_data = None
        
        if isinstance(content, str):
            try:
                # Try to parse as CSV
                lines = content.splitlines()
                reader = csv.reader(lines)
                data = list(reader)
                
                header = data[0] if len(data) > 0 else []
                
                # Convert rows to dictionaries if we have headers
                records = []
                if header and len(data) > 1:
                    for row in data[1:]:
                        # Ensure row has same length as header
                        padded_row = row + [''] * (len(header) - len(row)) if len(row) < len(header) else row[:len(header)]
                        records.append(dict(zip(header, padded_row)))
                
                structured_data = {
                    "header": header,
                    "rows": data[1:] if len(data) > 1 else [],
                    "records": records
                }
            except:
                # If parsing fails, return empty entities
                return entities
        elif isinstance(content, dict):
            # Check if this is our structured data format
            if all(k in content for k in ["header", "rows", "records"]):
                structured_data = content
            else:
                # Not in our expected format
                return entities
        else:
            # Unsupported content type
            return entities
        
        if not structured_data:
            return entities
        
        # Extract column headers as entities
        for col in structured_data["header"]:
            if col:  # Skip empty headers
                entities.append({
                    "type": "column_header",
                    "value": col,
                    "confidence": 1.0
                })
                
                # Detect column type
                col_type = self._detect_column_type(structured_data["rows"], structured_data["header"].index(col))
                if col_type != "mixed":
                    entities.append({
                        "type": "column_type",
                        "value": col_type,
                        "parent": col,
                        "confidence": 0.9
                    })
        
        # Extract values from cells that might contain entities
        for record_idx, record in enumerate(structured_data["records"]):
            for col, value in record.items():
                if isinstance(value, str) and value and len(value) > 3:
                    entity_type = self._detect_string_entity_type(value)
                    if entity_type:
                        entities.append({
                            "type": entity_type,
                            "value": value,
                            "column": col,
                            "row": record_idx + 1,  # Add 1 because records don't include header
                            "confidence": 0.8
                        })
        
        return entities
    
    def extract_metadata(self, content: Union[str, Dict[str, Any], Any]) -> Dict[str, Any]:
        """
        Extract metadata from CSV content.
        
        Args:
            content: CSV content as string, dict, or parsed CSV
            
        Returns:
            Dictionary of metadata
        """
        metadata: Dict[str, Any] = {
            "format": "csv",
            "content_type": "tabular"
        }
        
        # Handle different content types
        structured_data = None
        
        if isinstance(content, str):
            try:
                # Try to parse as CSV
                lines = content.splitlines()
                reader = csv.reader(lines)
                data = list(reader)
                
                header = data[0] if len(data) > 0 else []
                
                structured_data = {
                    "header": header,
                    "rows": data[1:] if len(data) > 1 else [],
                    "records": []  # We don't need records for metadata
                }
            except:
                # If parsing fails, return basic metadata
                return metadata
        elif isinstance(content, dict):
            # Check if this is our structured data format
            if all(k in content for k in ["header", "rows"]):
                structured_data = content
            else:
                # Not in our expected format
                return metadata
        else:
            # Unsupported content type
            return metadata
        
        if not structured_data:
            return metadata
        
        # Extract basic statistics
        row_count = len(structured_data["rows"])
        col_count = len(structured_data["header"])
        
        metadata["row_count"] = row_count
        metadata["column_count"] = col_count
        
        if col_count > 0:
            metadata["columns"] = structured_data["header"]
            
            # Analyze column types
            column_types = {}
            for i, col in enumerate(structured_data["header"]):
                if col:  # Skip empty headers
                    col_type = self._detect_column_type(structured_data["rows"], i)
                    column_types[col] = col_type
                    
            metadata["column_types"] = column_types
        
        # Detect if this might be a special type of CSV
        if col_count >= 2:
            # Check for time series data
            if any(h.lower() in ["date", "time", "timestamp", "year", "month", "day"] for h in structured_data["header"]):
                metadata["possible_data_type"] = "time_series"
                
            # Check for geographical data
            if any(h.lower() in ["country", "city", "state", "province", "region", "latitude", "longitude", "lat", "long", "zip", "postal"] for h in structured_data["header"]):
                metadata["possible_data_type"] = "geographical"
                
        return metadata
    
    def convert_to_markdown(self, content: Union[str, Dict[str, Any]]) -> str:
        """
        Convert CSV content to markdown format.
        
        Args:
            content: CSV content as string or dictionary
            
        Returns:
            Markdown representation of the CSV content
        """
        if isinstance(content, dict):
            if "content" in content:
                return content["content"]
            elif "structured_data" in content:
                return self.to_markdown(content["structured_data"])
        elif isinstance(content, str):
            # Try to parse CSV and convert to markdown table
            try:
                lines = content.splitlines()
                reader = csv.reader(lines)
                data = list(reader)
                
                if not data:
                    return f"```\n{content}\n```"
                
                # Convert to markdown table
                result = []
                header = data[0] if data else []
                
                if header:
                    result.append("| " + " | ".join(header) + " |")
                    result.append("| " + " | ".join(["---"] * len(header)) + " |")
                    
                    for row in data[1:]:
                        # Ensure row has same length as header
                        padded_row = row + [''] * (len(header) - len(row)) if len(row) < len(header) else row[:len(header)]
                        result.append("| " + " | ".join(padded_row) + " |")
                    
                    return "\n".join(result)
                else:
                    return f"```\n{content}\n```"
            except:
                return f"```\n{content}\n```"
                
        return self.to_markdown(content)
    
    def convert_to_text(self, content: Union[str, Dict[str, Any]]) -> str:
        """
        Convert CSV content to plain text.
        
        Args:
            content: CSV content as string or dictionary
            
        Returns:
            Plain text representation of the CSV content
        """
        if isinstance(content, dict):
            if "content" in content:
                return content["content"]
            elif "structured_data" in content:
                # Convert structured data back to CSV
                output = []
                data = content["structured_data"]
                
                if "header" in data and data["header"]:
                    output.append(",".join(data["header"]))
                
                if "rows" in data:
                    for row in data["rows"]:
                        output.append(",".join(row))
                
                return "\n".join(output)
        elif isinstance(content, str):
            return content
                
        return str(content)
    
    def to_markdown(self, content: Any) -> str:
        """
        Convert CSV content to markdown format.
        
        Args:
            content: CSV content to convert
            
        Returns:
            Markdown representation of the CSV content
        """
        if isinstance(content, str):
            try:
                # Try to parse as CSV
                lines = content.splitlines()
                reader = csv.reader(lines)
                data = list(reader)
                
                header = data[0] if len(data) > 0 else []
                rows = data[1:] if len(data) > 1 else []
            except:
                # If parsing fails, return the original text
                return f"```\n{content}\n```"
        elif isinstance(content, dict) and all(k in content for k in ["header", "rows"]):
            header = content["header"]
            rows = content["rows"]
        else:
            # Unsupported format
            return "Unsupported CSV format"
        
        # Generate markdown table
        result = []
        
        # Add header
        if header:
            result.append("| " + " | ".join(header) + " |")
            result.append("| " + " | ".join(["---"] * len(header)) + " |")
            
            # Add rows (limit to avoid excessively long tables)
            max_rows = 50
            for i, row in enumerate(rows):
                if i >= max_rows:
                    result.append(f"\n*... {len(rows) - max_rows} more rows omitted ...*")
                    break
                    
                # Ensure row has same length as header
                padded_row = row + [''] * (len(header) - len(row)) if len(row) < len(header) else row[:len(header)]
                # Escape pipe characters in cell values
                escaped_row = [cell.replace('|', '\\|') for cell in padded_row]
                result.append("| " + " | ".join(escaped_row) + " |")
        else:
            # No header, just show raw data
            result.append("```")
            for row in rows[:20]:  # Limit to 20 rows
                result.append(",".join(row))
            if len(rows) > 20:
    
    Args:
        content: CSV content to convert
        
    Returns:
        Markdown representation of the CSV content
    """
    if isinstance(content, str):
        try:
            # Try to parse as CSV
            lines = content.splitlines()
            reader = csv.reader(lines)
            data = list(reader)
            
            header = data[0] if len(data) > 0 else []
            rows = data[1:] if len(data) > 1 else []
        except:
            # If parsing fails, return the original text
            return f"```\n{content}\n```"
    elif isinstance(content, dict) and all(k in content for k in ["header", "rows"]):
        header = content["header"]
        rows = content["rows"]
    else:
        # Unsupported format
        return "Unsupported CSV format"
    
    # Generate markdown table
    result = []
    
    # Add header
    if header:
        result.append("| " + " | ".join(header) + " |")
        result.append("| " + " | ".join(["---"] * len(header)) + " |")
        
        # Add rows (limit to avoid excessively long tables)
        max_rows = 50
        for i, row in enumerate(rows):
            if i >= max_rows:
                result.append(f"\n*... {len(rows) - max_rows} more rows omitted ...*")
                break
                
            # Ensure row has same length as header
            padded_row = row + [''] * (len(header) - len(row)) if len(row) < len(header) else row[:len(header)]
            # Escape pipe characters in cell values
            escaped_row = [cell.replace('|', '\\|') for cell in padded_row]
            result.append("| " + " | ".join(escaped_row) + " |")
    else:
        # No header, just show raw data
        result.append("```")
        for row in rows[:20]:  # Limit to 20 rows
            result.append(",".join(row))
        if len(rows) > 20:
            result.append(f"... {len(rows) - 20} more rows ...")
        result.append("```")
            rows: List of data rows
            col_idx: Column index to analyze
            
        Returns:
            Detected data type
        """
        # Collect non-empty values from the column
        values = []
        for row in rows:
            if col_idx < len(row) and row[col_idx].strip():
                values.append(row[col_idx].strip())
        
        if not values:
            return "empty"
            
        # Check if all values are numeric
        numeric_count = sum(1 for v in values if re.match(r'^-?\d+(\.\d+)?$', v))
        
        # Check if all values are dates (simple check)
        date_count = sum(1 for v in values if re.match(r'^\d{1,4}[-/]\d{1,2}[-/]\d{1,4}$', v) or 
                                               re.match(r'^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}', v))
        
        # Check if all values are boolean-like
        bool_count = sum(1 for v in values if v.lower() in ['true', 'false', 'yes', 'no', '0', '1', 'y', 'n'])
        
        # Determine type based on most common pattern
        total = len(values)
        
        if numeric_count / total > 0.8:
            return "numeric"
        elif date_count / total > 0.8:
            return "date"
        elif bool_count / total > 0.8:
            return "boolean"
        else:
            return "text" if total > 0 else "mixed"
    
    def _detect_string_entity_type(self, value: str) -> Optional[str]:
        """
        Detect if a string value represents a specific entity type.
        
        Args:
            value: String value to analyze
            
        Returns:
            Detected entity type or None
        """
        # Convert to string if not already
        if not isinstance(value, str):
            value = str(value)
        
        # Check for common patterns
        value = value.strip()
        
        # Empty string
        if not value:
            return None
            
        # Email pattern
        if re.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$', value):
            return "email"
            
        # URL pattern
        if re.match(r'^(https?|ftp)://[^\s/$.?#].[^\s]*$', value):
            return "url"
            
        # Date pattern
        if re.match(r'^\d{4}-\d{2}-\d{2}$', value) or re.match(r'^\d{2}/\d{2}/\d{4}$', value):
            return "date"
            
        # Person name heuristic (simplified)
        if re.match(r'^[A-Z][a-z]+ [A-Z][a-z]+$', value):
            return "person_name"
            
        # Phone number pattern (simplified)
        if re.match(r'^\+?[\d\s\(\)-]{7,20}$', value) and any(c.isdigit() for c in value):
            return "phone_number"
            
        # Currency
        if re.match(r'^[$€£¥](\d{1,3}(,\d{3})*|\d+)(\.\d{2})?$', value):
            return "currency"
            
        # Postal/Zip code patterns
        if re.match(r'^\d{5}(-\d{4})?$', value):  # US
            return "postal_code"
            
        # No specific pattern detected
        return None


# Register the adapter
register_adapter('csv', CSVAdapter)
