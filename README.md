# HADES-PathRAG

Enhanced implementation of **PathRAG: Pruning Graph-based Retrieval Augmented Generation with Relational Paths** with ArangoDB integration and **vLLM support** for high-performance local LLM inference.

## Features

- üîç **PathRAG Implementation**: Efficient graph-based RAG that prunes retrieval paths
- üß† **vLLM Integration**: High-performance inference engine for local model serving
- üìä **ArangoDB Support**: Scalable graph database backend for enterprise use
- üîÑ **ISNE Embedding**: Inductive Shallow Node Embedding for semantic understanding
- üöÄ **FastAPI Interface**: Simple, lightweight API for system interaction
- üîß **Type-Safe Implementation**: Fully type-annotated codebase for reliability

## Install

```bash
# Clone the repository
git clone https://github.com/r3d91ll/HADES-PathRAG.git
cd HADES-PathRAG

# Install dependencies
pip install -e .

# Set up vLLM for local inference
pip install vllm

# (Optional) Install ArangoDB if not already installed
# Follow instructions at https://www.arangodb.com/download/
```

## Quick Start

- You can quickly experience this project in the `v1_test.py` file.
- Set OpenAI API key in environment if using OpenAI models: `api_key="sk-...".` in the `v1_test.py` and `llm.py` file
- Prepare your retrieval document "text.txt".
- Use the following Python snippet in the "v1_text.py" file to initialize PathRAG and perform queries.
  
```python
import os
from pathrag import PathRAG, QueryParam

# For using vLLM (no API keys needed)
from pathrag.llm import vllm_model_complete

# For using OpenAI (if preferred)
# from pathrag.llm import openai_complete
# os.environ["OPENAI_API_KEY"] = "your_api_key"

WORKING_DIR = "./your_working_dir"
if not os.path.exists(WORKING_DIR):
    os.mkdir(WORKING_DIR)

# Initialize with vLLM as the LLM provider
rag = PathRAG(
    working_dir=WORKING_DIR,
    llm_model_func=lambda prompt, **kwargs: vllm_model_complete(
        prompt=prompt,
        model="mistralai/Mistral-7B-Instruct-v0.2"
    )
)

data_file="./text.txt"
question="your_question"
with open(data_file) as f:
    rag.insert(f.read())

print(rag.query(question, param=QueryParam(mode="hybrid")))
```

## Parameter modification

You can adjust the relevant parameters in the `base.py` and `operate.py` files.

## Batch Insert

```python
import os
folder_path = "your_folder_path"  

txt_files = [f for f in os.listdir(folder_path) if f.endswith(".txt")]
for file_name in txt_files:
    file_path = os.path.join(folder_path, file_name)
    with open(file_path, "r", encoding="utf-8") as file:
        rag.insert(file.read())
```

## Cite

Please cite our paper if you use this code in your own work:

```python
@article{chen2025pathrag,
  title={PathRAG: Pruning Graph-based Retrieval Augmented Generation with Relational Paths},
  author={Chen, Boyu and Guo, Zirui and Yang, Zidan and Chen, Yuluo and Chen, Junze and Liu, Zhenghao and Shi, Chuan and Yang, Cheng},
  journal={arXiv preprint arXiv:2502.14902},
  year={2025}
}
```

## HADES: Enhanced PathRAG Implementation

This project contains an advanced implementation of PathRAG that integrates ArangoDB and vLLM for high-performance knowledge graph retrieval. For detailed documentation, see our [Ingestion System](./docs/ingestion_system.md), [Chunking Strategy](./docs/chunking.md), and [API Reference](./docs/api.md).

## Documentation Structure

The `/docs` directory contains comprehensive documentation organized as follows:

### Core Components

- [Ingestion System](./docs/ingestion_system.md) - Complete ingestion pipeline and incremental update process
- [Chunking Strategy](./docs/chunking.md) - Hybrid chunking with semantic and code-aware approaches
- [API Reference](./docs/api.md) - FastAPI interface for the PathRAG system

### Integration Guides

- [ArangoDB Setup](./docs/integration/arango_setup.md) - Setting up ArangoDB for HADES
- [Docker Deployment](./docs/integration/docker_deployment.md) - Containerized deployment
- [GitHub Ingestion](./docs/integration/github_ingestion.md) - Ingesting code from GitHub repositories

### Original Research

- [Academic Papers](./docs/original_paper/) - Research foundation for PathRAG

### Experimental Features

- [XnX Notation](./docs/xnx/) - Documentation for experimental relationship notation

### What is HADES?

HADES represents our approach to building a powerful, type-safe knowledge retrieval system:

- **H**euristic approach to knowledge representation and retrieval
- **A**daptive graph traversal with relationship-aware path ranking
- **D**ata-centric with efficient ArangoDB storage and incremental updates
- **E**xtrapolation capabilities for models using retrieved context
- **S**ystem designed as a network of interconnected processes

### Key Enhancements

- **Incremental Knowledge Graph**: Support for updating individual nodes and relationships
- **ArangoDB Integration**: Optimized graph storage with combined vector and graph operations
- **FastAPI Interface**: Simple REST API for interaction with the system
- **vLLM Integration**: High-performance inference for improved throughput
- **ISNE Embedding**: Advanced embedding approach that captures relationship information

Run `python -m src.api.cli` to launch the API server interface.

## Development Roadmap

### Completed

- ‚úÖ Basic PathRAG implementation with ArangoDB support
- ‚úÖ Type-safe base interfaces for embeddings, storage, and graph operations
- ‚úÖ Python pre-processor with symbol table support
- ‚úÖ Ingestion pipeline documentation and design
- ‚úÖ FastAPI server implementation

### In Progress

- üîÑ Docling pre-processor improvements
- üîÑ Hybrid chunking implementation (Chonky + code-aware)
- üîÑ ISNE embedding integration
- üîÑ Incremental update support

### Planned

- üìÖ Integration tests for full pipeline
- üìÖ Performance optimization (parallelism)
- üìÖ vLLM integration for inference
- üìÖ Web interface development
- üìÖ XnX notation support (experimental)
