"""
Unit tests for the ISNE Training Orchestrator.

This module contains tests for the ISNETrainingOrchestrator class, which is responsible for
coordinating the training of the ISNE model using document embeddings and relationships
generated by the document processing pipeline.
"""

import os
import json
import shutil
import tempfile
import unittest
from pathlib import Path
from unittest.mock import patch, MagicMock, Mock

import torch
import numpy as np
from torch_geometric.data import Data

import sys
# Add project root to path
project_root = Path(__file__).parents[3].absolute()
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from src.isne.trainer.training_orchestrator import ISNETrainingOrchestrator


class TestISNETrainingOrchestrator(unittest.TestCase):
    """
    Test case for the ISNETrainingOrchestrator class.
    
    These tests verify the functionality of the ISNE training orchestrator,
    including configuration loading, graph construction, and training workflows.
    """
    
    def setUp(self):
        """Set up test environment before each test."""
        # Create temporary directories for testing
        self.temp_dir = tempfile.mkdtemp()
        self.input_dir = Path(self.temp_dir) / "input"
        self.output_dir = Path(self.temp_dir) / "output"
        self.model_dir = Path(self.temp_dir) / "models"
        
        # Create directory structure
        self.input_dir.mkdir(parents=True, exist_ok=True)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.model_dir.mkdir(parents=True, exist_ok=True)
        
        # Create a sample ISNE input file
        self.sample_documents = [
            {
                "file_id": "test_doc_1",
                "file_name": "test_doc_1.txt",
                "chunk_count": 3,
                "embedding_count": 3,
                "chunks": [
                    {
                        "id": "chunk_1",
                        "content": "This is test chunk 1",
                        "embedding": [0.1] * 768,
                        "overlap_context": {
                            "position": 0,
                            "total": 3
                        }
                    },
                    {
                        "id": "chunk_2",
                        "content": "This is test chunk 2",
                        "embedding": [0.2] * 768,
                        "overlap_context": {
                            "position": 1,
                            "total": 3
                        }
                    },
                    {
                        "id": "chunk_3",
                        "content": "This is test chunk 3",
                        "embedding": [0.3] * 768,
                        "overlap_context": {
                            "position": 2,
                            "total": 3
                        }
                    }
                ]
            }
        ]
        
        self.sample_stats = {
            "total_files": 1,
            "total_chunks": 3,
            "total_embeddings": 3,
            "processing_time": {
                "document_processing": 0.1,
                "chunking": 0.1,
                "embedding": 0.1,
                "total": 0.3
            }
        }
        
        # Write sample files
        with open(self.input_dir / "isne_input_sample.json", "w") as f:
            json.dump(self.sample_documents, f)
        
        with open(self.input_dir / "pipeline_stats.json", "w") as f:
            json.dump(self.sample_stats, f)
    
    def tearDown(self):
        """Clean up test environment after each test."""
        # Remove temporary directory
        shutil.rmtree(self.temp_dir)
    
    def test_initialization(self):
        """Test the initialization of the ISNETrainingOrchestrator."""
        # Initialize orchestrator with explicit directories
        orchestrator = ISNETrainingOrchestrator(
            input_dir=self.input_dir,
            output_dir=self.output_dir,
            model_output_dir=self.model_dir
        )
        
        # Check that directories are set correctly
        self.assertEqual(orchestrator.input_dir, self.input_dir)
        self.assertEqual(orchestrator.output_dir, self.output_dir)
        self.assertEqual(orchestrator.model_output_dir, self.model_dir)
        
        # Check that config is loaded with all required sections
        self.assertIn("isne", orchestrator.config)
        self.assertIn("model", orchestrator.config["isne"])
        self.assertIn("training", orchestrator.config["isne"])
        self.assertIn("graph", orchestrator.config["isne"])
        self.assertIn("directories", orchestrator.config["isne"])
        
        # Test initialization with None directories (should use config defaults)
        orchestrator = ISNETrainingOrchestrator()
        
        # Directories should be Path objects
        self.assertIsInstance(orchestrator.input_dir, Path)
        self.assertIsInstance(orchestrator.output_dir, Path)
        self.assertIsInstance(orchestrator.model_output_dir, Path)
        
        # The directories should match the defaults from config
        dir_config = orchestrator.config["isne"]["directories"]
        self.assertEqual(orchestrator.input_dir, Path(dir_config["input_dir"]))
        self.assertEqual(orchestrator.output_dir, Path(dir_config["output_dir"]))
        self.assertEqual(orchestrator.model_output_dir, Path(dir_config["model_dir"]))
    
    def test_config_override(self):
        """Test configuration override functionality."""
        # Define override with the new hierarchical structure
        override = {
            "isne": {
                "training": {
                    "epochs": 100,
                    "learning_rate": 0.0005
                },
                "model": {
                    "hidden_dim": 512
                }
            }
        }
        
        # Initialize orchestrator with override
        orchestrator = ISNETrainingOrchestrator(
            input_dir=self.input_dir,
            config_override=override
        )
        
        # Check that training overrides are applied
        self.assertEqual(orchestrator.config["isne"]["training"]["epochs"], 100)
        self.assertEqual(orchestrator.config["isne"]["training"]["learning_rate"], 0.0005)
        
        # Check that model overrides are applied
        self.assertEqual(orchestrator.config["isne"]["model"]["hidden_dim"], 512)
        
        # Test with flat override structure too
        flat_override = {
            "training": {
                "batch_size": 64,
                "checkpoint_interval": 10
            }
        }
        
        orchestrator = ISNETrainingOrchestrator(
            input_dir=self.input_dir,
            config_override=flat_override
        )
        
        self.assertEqual(orchestrator.config["isne"]["training"]["batch_size"], 64)
        self.assertEqual(orchestrator.config["isne"]["training"]["checkpoint_interval"], 10)
    
    def test_load_pipeline_output(self):
        """Test loading output from the pipeline."""
        # Initialize orchestrator
        orchestrator = ISNETrainingOrchestrator(
            input_dir=self.input_dir
        )
        
        # Load pipeline output
        documents, stats = orchestrator._load_pipeline_output()
        
        # Check loaded data
        self.assertEqual(len(documents), 1)
        self.assertEqual(documents[0]["file_id"], "test_doc_1")
        self.assertEqual(len(documents[0]["chunks"]), 3)
        
        # Check stats
        self.assertEqual(stats["total_files"], 1)
        self.assertEqual(stats["total_chunks"], 3)
    
    def test_config_graph_parameters(self):
        """Test that graph construction parameters from config are properly set."""
        # Initialize orchestrator with custom graph parameters
        graph_config_override = {
            "isne": {
                "graph": {
                    "window_size": 2,
                    "sequential_weight": 0.8,
                    "similarity_weight": 0.6
                }
            }
        }
        
        orchestrator = ISNETrainingOrchestrator(
            input_dir=self.input_dir,
            config_override=graph_config_override
        )
        
        # Verify config values were set correctly
        self.assertEqual(orchestrator.config["isne"]["graph"]["window_size"], 2)
        self.assertEqual(orchestrator.config["isne"]["graph"]["sequential_weight"], 0.8)
        self.assertEqual(orchestrator.config["isne"]["graph"]["similarity_weight"], 0.6)
    
    @patch("src.isne.trainer.training_orchestrator.ISNETrainingOrchestrator._construct_graph")
    def test_construct_graph(self, mock_construct_graph):
        """Test graph construction from documents."""
        # Create mock graph data
        mock_graph = Data(
            x=torch.ones(3, 768),  # 3 nodes with 768 features each
            edge_index=torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]], dtype=torch.long),  # 4 edges in COO format
            edge_attr=torch.ones(4),  # 4 edge weights
            num_nodes=3
        )
        
        # Configure mock to return our graph
        mock_construct_graph.return_value = mock_graph
        
        # Initialize orchestrator with default config
        orchestrator = ISNETrainingOrchestrator(
            input_dir=self.input_dir
        )
        
        # Call the method that would use _construct_graph
        documents, _ = orchestrator._load_pipeline_output()
        graph = orchestrator._construct_graph(documents)
        
        # Verify mock was called with correct documents
        mock_construct_graph.assert_called_once_with(documents)
        
        # Check graph structure matches our mock
        self.assertIsInstance(graph, Data)
        self.assertEqual(graph.num_nodes, 3) 
        self.assertEqual(graph.num_edges, 4)
    
    @patch("src.isne.trainer.training_orchestrator.ISNETrainer")
    def test_prepare_trainer(self, mock_trainer_class):
        """Test preparation of the ISNE trainer."""
        # Mock trainer
        mock_trainer = Mock()
        mock_trainer_class.return_value = mock_trainer
        
        # Initialize orchestrator
        orchestrator = ISNETrainingOrchestrator(
            input_dir=self.input_dir
        )
        
        # Prepare trainer
        trainer = orchestrator._prepare_trainer()
        
        # Check that trainer was initialized with the correct parameters
        mock_trainer_class.assert_called_once()
        call_args = mock_trainer_class.call_args[1]
        
        # Verify that parameters from both model and training sections are used
        self.assertIn('embedding_dim', call_args)  # from model section
        self.assertIn('hidden_dim', call_args)     # from model section
        self.assertIn('learning_rate', call_args)  # from training section
        self.assertIn('lambda_feat', call_args)    # from training section
        
        mock_trainer.prepare_model.assert_called_once()
        
        # Check that trainer is returned
        self.assertEqual(trainer, mock_trainer)
    
    @patch("src.isne.trainer.training_orchestrator.ISNETrainingOrchestrator._load_pipeline_output")
    @patch("src.isne.trainer.training_orchestrator.ISNETrainingOrchestrator._construct_graph")
    @patch("src.isne.trainer.training_orchestrator.ISNETrainingOrchestrator._prepare_trainer")
    def test_train(self, mock_prepare_trainer, mock_construct_graph, mock_load_output):
        """Test the full training workflow."""
        # Mock pipeline output
        mock_load_output.return_value = (self.sample_documents, self.sample_stats)
        
        # Mock graph construction
        mock_graph = Mock()
        mock_graph.x = torch.tensor([[0.1] * 768, [0.2] * 768, [0.3] * 768])
        mock_graph.edge_index = torch.tensor([[0, 1], [1, 2]])
        mock_construct_graph.return_value = mock_graph
        
        # Mock trainer
        mock_trainer = Mock()
        mock_trainer.train.return_value = {
            "epochs": 10,
            "total_loss": [1.0, 0.9, 0.8],
            "feature_loss": [0.5, 0.4, 0.3],
            "structural_loss": [0.3, 0.3, 0.3],
            "contrastive_loss": [0.2, 0.2, 0.2]
        }
        mock_prepare_trainer.return_value = mock_trainer
        
        # Initialize orchestrator
        orchestrator = ISNETrainingOrchestrator(
            input_dir=self.input_dir,
            output_dir=self.output_dir,
            model_output_dir=self.model_dir
        )
        
        # Run training
        metrics = orchestrator.train()
        
        # Check training workflow
        mock_load_output.assert_called_once()
        mock_construct_graph.assert_called_once_with(self.sample_documents)
        mock_prepare_trainer.assert_called_once()
        mock_trainer.train.assert_called_once()
        mock_trainer.save_model.assert_called_once()
        
        # Check metrics
        self.assertEqual(metrics["epochs"], 10)
        self.assertIn("duration", metrics)
        self.assertIn("losses", metrics)
    
    @patch("src.isne.trainer.training_orchestrator.ISNETrainingOrchestrator._prepare_trainer")
    def test_load_model(self, mock_prepare_trainer):
        """Test loading a trained model."""
        # Mock trainer
        mock_trainer = Mock()
        mock_prepare_trainer.return_value = mock_trainer
        
        # Create dummy model file
        model_path = self.model_dir / "isne_model_latest.pt"
        with open(model_path, "w") as f:
            f.write("dummy model data")
        
        # Initialize orchestrator
        orchestrator = ISNETrainingOrchestrator(
            input_dir=self.input_dir,
            model_output_dir=self.model_dir
        )
        
        # Load model
        orchestrator.load_model()
        
        # Check model loading
        mock_prepare_trainer.assert_called_once()
        mock_trainer.load_model.assert_called_once_with(model_path)


class TestISNETrainingOrchestratorPerformance(unittest.TestCase):
    """
    Performance tests for the ISNETrainingOrchestrator.
    
    These tests measure the performance characteristics of the ISNE training
    orchestrator, focusing on computation time and memory usage.
    """
    
    @unittest.skip("Performance tests are resource-intensive and should be run manually")
    def test_graph_construction_performance(self):
        """Test the performance of graph construction for different document sizes."""
        # Create sample documents of different sizes
        small_docs = self._create_sample_docs(10, 5)  # 10 documents, 5 chunks each
        medium_docs = self._create_sample_docs(50, 10)  # 50 documents, 10 chunks each
        large_docs = self._create_sample_docs(100, 20)  # 100 documents, 20 chunks each
        
        # Measure performance for each size
        orchestrator = ISNETrainingOrchestrator(input_dir=Path("."))
        
        # Small dataset
        start_time = time.time()
        small_graph = orchestrator._construct_graph(small_docs)
        small_time = time.time() - start_time
        print(f"Small graph construction: {small_time:.2f}s, {small_graph.num_nodes} nodes, {small_graph.num_edges} edges")
        
        # Medium dataset
        start_time = time.time()
        medium_graph = orchestrator._construct_graph(medium_docs)
        medium_time = time.time() - start_time
        print(f"Medium graph construction: {medium_time:.2f}s, {medium_graph.num_nodes} nodes, {medium_graph.num_edges} edges")
        
        # Large dataset
        start_time = time.time()
        large_graph = orchestrator._construct_graph(large_docs)
        large_time = time.time() - start_time
        print(f"Large graph construction: {large_time:.2f}s, {large_graph.num_nodes} nodes, {large_graph.num_edges} edges")
    
    def _create_sample_docs(self, num_docs, chunks_per_doc):
        """Helper method to create sample documents for performance testing."""
        docs = []
        for i in range(num_docs):
            chunks = []
            for j in range(chunks_per_doc):
                chunks.append({
                    "id": f"doc_{i}_chunk_{j}",
                    "content": f"Content for document {i}, chunk {j}",
                    "embedding": np.random.rand(768).tolist(),
                    "overlap_context": {
                        "position": j,
                        "total": chunks_per_doc
                    }
                })
            
            docs.append({
                "file_id": f"doc_{i}",
                "file_name": f"doc_{i}.txt",
                "chunk_count": chunks_per_doc,
                "embedding_count": chunks_per_doc,
                "chunks": chunks
            })
        
        return docs


if __name__ == "__main__":
    unittest.main()
